---
title: "HUDM6026 Homework_10"
author: Chenguang Pan & Seng Lei
date: April 04, 2023
output:
  pdf_document:
    toc: false
    toc_depth: 6
    number_sections: true
    keep_tex: true
    highlight: tang
---

```{r setup, include=FALSE}
## Global options
knitr::opts_chunk$set(
  cache = TRUE,
  prompt = TRUE,
  comment = '',
  collapse = TRUE,
  warning = FALSE,
  message = FALSE)
```   

## ISLR_Chapter 6.10  
*We have seen that as the number of features used in a model increases, the training error will necessarily decrease, but the test error may not. We will now explore this in a simulated data set.*  

### (a)  
*Generate a data set with p = 20 features, n = 1,000 observations, and an associated quantitative response vector generated according to the model*  

**MY SOLUTION:**  

Thinking multiple variate regression in matrix form provides a more efficient way to estimate or simulate. Since generating the multivariate normal distribution needs the connivance matrix and mean vector, like shown in Dr.Keller's in-class R syntax, we need to define them first.

```{r}
# import the packages
library(mvtnorm)
library(clusterGeneration)

# ---------------------
# STAGE 1 PREPARE
# ---------------------
# set the random seed
set.seed(666)
# Generate a random covariance matrix with package clusterGeneration
cov1 <- genPositiveDefMat(dim=20, # create 20 covariates
                          covMethod = "eigen")
# Generate a random vector of 20 means from a normal distribution with N(0, 20)
mns1 <- rnorm(20,0,sd=20)
# Generate coefficients vector for the output for Y from norm(0, 1)  
coef1 <- rnorm(21, # Beta0 + Beta1 +...+ Beta20
               0,1) # drawn from a normal distribution N(0,1)
### Set ten of them equal to zero
coef1[sample(2:21, 10, replace = FALSE)] <- 0

# ---------------------------------------
# STAGE 2 BUILD DATA GENERATING FUNCTION
# ---------------------------------------
dataGen <- function(N){
  # Generate the X matrix 
  X <- rmvnorm(n=N, mean = mns1,sigma = cov1$Sigma)
  # augmenting the X matrix
  X_aug <- cbind(1,X)
  # create the output Y with error term vector following the N(0,1)
  Y <- X_aug %*% coef1 + rnorm(N,0,1)
  # adjust the output
  dfOut <-  data.frame(cbind(X,Y))
  names(dfOut) <- c(paste0("X",1:20), "Y")
  return(dfOut)
}

# ----------------------
# STAGE 3 GENERATE DATA
# ----------------------
df <- dataGen(1000)
head(df)
dim(df)
```  
The data looks good.  

### (b)  
*Split your dataset into a training set containing 100 observations and a test set containing 900 observations.*  

**MY SOLUTION:**  
```{r}
# generate a random index from 1:1000 
set.seed(666)
index_rdm <- sample(c(1:1000),100)
# separate the dataset into train and test dataset
df_train <- df[index_rdm,]
df_test <- df[-index_rdm,]
dim(df_train)
dim(df_test)
```  
The randomly-subseted train- and test-dataset look good.  

### (c)  
*Perform best subset selection on the training set, and plot the training set MSE associated with the best model of each size.*  

**MY SOLUTION:**  
```{r}
library(bestglm)
bss_out <- regsubsets(Y ~., data = df_train, nvmax=20)
bss_out_summary <- summary(bss_out)
```  
Note, by default, the `regsubsets()` only returns the first 8 models.  
Based on the definition, we can get easily get the MSE since $MSE = \frac{RSS}{n}$.
```{r,fig.show='hold',out.width="50%",out.height= "50%"}
plot(bss_out_summary$rss/nrow(df_train),
     xlab = "Number of Vairables",
     ylab = "MSE",
     type = "l")
title(main = "Figure 1. Training set MSE associated with the best model of each size.", 
      cex.main = 1)
```  

### (d)  
*Plot the test set MSE associated with the best model of each size.*  

**MY SOLUTION:**  
Since there is no `predict()` function built in the `regsubsets()`, I need to write by hand.
```{r} 
# note the test dataset is in data.frame format need to be change to matrix
df_test_matrix <- as.matrix(df_test)
names(coef(bss_out, id=2))[-1]

test_mse <- c()
for (i in 1:20) {
  # to extract the coefficient vector for each best model
  coefi <- coef(bss_out, id=i)
  # select the corresponding variables and times the coefficients
  X_temp <- df_test_matrix[,names(coefi)[-1]]
  X_temp_aug <- cbind(1, X_temp)
  pred <- X_temp_aug %*% coefi
  # use the estimated vector of outcome to get the MSE
  mse <- mean((df_test[,"Y"]-pred)^2)
  test_mse[i] <- mse
}
test_mse
```  
The result looks good. Next, I plot the MSE.
```{r,fig.show='hold',out.width="50%",out.height= "50%"}
plot(test_mse,
     xlab = "Number of Vairables",
     ylab = "MSE",
     type = "l")
title(main = "Figure 2. Test-set MSE associated with the best model of each size.", 
      cex.main = 1)
min_index <- which.min(test_mse)
points(min_index,test_mse[min_index],col="red",cex=2, pch=20)
abline(h=min(test_mse), col="red",lty="longdash")
```  

### (e)  
*For which model size does the test set MSE take on its minimum value? Comment on your results.*  

**MY SOLUTION:**    
*Figure 2* shows that the model with 10 predictors has the lowest test MSE. From the results below, the ten covariates are $X1$,$X4$,$X7$,$X9$,$X10$,$X13$,$X14$,$X15$,$X19$, and $X20$.
```{r}
bss_out_summary$outmat[10,]
```  

### (f)  
*How does the model at which the test set MSE is minimized compare to the true model used to generate the data? *  

**MY SOLUTION:**  
```{r}
# extract the estimated 10-predictor model's coefficient
round(coef(bss_out,id=10),3)
# extract the original 10-predictor model's coefficient
original_coef <- as.data.frame(matrix(round(coef1[which(coef1 !=0)],3),
                                      1,11,byrow=T))
names(original_coef) <- c("Intercept","X1","X4","X7","X9","X10","X13","X14","X15","X19", "X20")
original_coef
```  
Comparing the estimated coefficients and the original coefficients, we can see that:  
- first, the number of the coefficient are the same;  
- second, the value of each estimated coefficient is very close to the original one;  


### (g)  
*Create a plot displaying ... for a range of values of r, where . is the jth coeffcicient for the best model containing r coeeficients.Comment on what you observe. How does this compare to the test MSE plot from (d) *  

**MY SOLUTION:**  
```{r}
coef1
```  
To solve this question, we need to manipulate the strings (a.k.a., the characters) to extract the selected variables and their index number. Here, I use the package `stringr`.
```{r}
# install.packages("stringr")
library(stringr)
beta_errors <- c()
for (i in 1:20) {
  # to extract the best coefficient and corresponding variables
  coef_temp <- (coef(bss_out,id=i))
  # to construct a dataframe for processing convenience
  coef_temp_df <- as.data.frame(t(as.matrix(coef_temp)))
  # make a null matrix(vector) with the size of 1*21
  coef_temp_vec <- as.vector(rep(0,21))
  # mapping all model-selected variables's names
  for(name in names(coef_temp_df[-1])) {
    # extract the location information
    var_location <- as.numeric(str_sub(name, start = 2))
    # write the coefficient to corresponding location
    coef_temp_vec[var_location+1] <- coef_temp_df[1,name]
  }
  coef_temp_vec[1] <- coef_temp[1]
  
  # to subtract the original coefficient vector and the estimated vector
  beta_error <- as.vector(coef1)- coef_temp_vec
  out_ <- sqrt(t(beta_error) %*% beta_error)
  
  # write the outcome into the beta_errors set
  beta_errors[i] <- out_
}

round(beta_errors,3)
```  
The results looks good. Next, I plot the beta errors.  
```{r,fig.show='hold',out.width="50%",out.height= "50%"}
plot(beta_errors,
     xlab = "Number of Vairables",
     ylab = "Beta Errors",
     type = "l")
title(main = "Figure 3. Beta errors for each size.", 
      cex.main = 1)
min_index <- which.min(beta_errors)
points(min_index,beta_errors[min_index],col="red",cex=2, pch=20)
abline(h=min(beta_errors), col="red",lty="longdash")
```   

From the plot we can see that this method selected the 7-predictors models as the best. However, we do not really know what is the performance on the testing dataset. We should not rely on this method to select the best model.









